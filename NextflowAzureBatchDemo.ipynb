{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "resident-bishop",
   "metadata": {},
   "source": [
    "# Execute Nextflow Pipeline with Azure Batch\n",
    "\n",
    "Nextflow has gained traction due to its ability to separate pipeline logic from the execution environments it runs on. This feature, coupled with its support for a variety of data protocols, source code management systems, container runtimes, and registries, empowers users to swiftly develop pipelines that can be deployed across different computing environments - from personal notebooks to large on-premises clusters and various cloud platforms.\n",
    "\n",
    "According to the recent State of the [Workflow 2022 Community Survey](https://seqera.io/blog/state-of-the-workflow-2022-results/), 36% of Nextflow users are currently running their pipelines in the cloud, and a significant 68% are planning to transition to cloud-based operations. [Azure Batch](https://learn.microsoft.com/en-us/azure/batch/) stands out as a preferred execution environment among Nextflow users. While the integration of Nextflow with Azure Batch simplifies cloud operations, it’s important to note that there’s a lot happening behind the scenes. Gaining a deeper understanding of this integration can lead to more efficient use of cloud resources and make it easier to troubleshoot potential issues.\n",
    "\n",
    "In this article, we take a closer look at using Nextflow with Azure Batch and explain how to set it up and how it works under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-ireland",
   "metadata": {},
   "source": [
    "## Azure Batch Concepts\n",
    "\n",
    "Like other modern cloud services, Azure Batch is feature-rich with many configuration options. Below are some terms and concepts that you will need to be familiar with:\n",
    "\n",
    "**Batch Account** – An Azure Batch Account is a uniquely identified entity within the Batch service. It’s used to create compute resources (pools of compute nodes) and Batch jobs. All processing and resources are associated with a Batch account. When your application makes a request against the Batch service, it authenticates the request using the Azure Batch account name, the URL of the account, and either an access key, or use Microsoft Entra authentication. As with other cloud services, there are limits on certain resources associated with Azure Batch. The Azure Batch documentation has a good explanation of [batch services quotas and limits](https://learn.microsoft.com/en-us/azure/batch/batch-quota-limit). For production scale pipelines, you will likely need to request an increase in quota.\n",
    "\n",
    "**Storage Account** – Most Batch solutions use Azure Storage for storing resource files and output files. For example, your Batch tasks (including standard tasks, start tasks, job preparation tasks, and job release tasks) typically specify resource files that reside in a storage account. Storage accounts also stores data that is processed and any output data that is generated. A corresponding storage account should be set up and associated with the batch account in the same cloud region for each batch account. For Nextflow, we will set up a container in Blob storage to act as a working directory for pipeline execution.\n",
    "\n",
    "**Nodes** – In Azure Batch, a node is an Azure virtual machine (VM) dedicated to processing a portion of an application’s workload. The size of a node (specified using a vm_type setting) determines the number of CPU cores, memory capacity, and local disk size allocated to the node.\n",
    "\n",
    "**Pools** – A pool in Azure Batch refers to a collection of nodes with the same configuration. Multiple named pools can be associated with a batch account, and Azure cloud administrators can specify the type of nodes and images associated with each pool. Pools can be created in advance or created dynamically in response to workload demand. Every node that is added to a pool is assigned a unique name and IP address. When a node is removed from a pool, any changes that are made to the operating system or files are lost, and its name and IP address are released for future use. When a node leaves a pool, its lifetime is over.\n",
    "\n",
    "**Jobs and tasks** – Unlike traditional workload managers, Azure Batch does not explicitly have the notion of queues, but Azure Batch jobs provide similar functionality. They manage dispatching tasks to pools, implement scheduling policies, auto-scaling resources, managing start tasks, and more. While a job is a collection of tasks, an Azure Batch task defines a unit of work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b95aac",
   "metadata": {},
   "source": [
    "## About the Integration\n",
    "\n",
    "The diagram below illustrates how the Nextflow – Azure Batch integration works. Azure administrators begin by setting up a storage service and a batch environment in the Azure cloud, recording the credentials for both services or setting up Microsoft Entra for authentication. While tasks can be sent to Azure Batch by Nextflow users from a local laptop or PC, we will set up a VM within the Azure cloud to submit jobs in this tutorial.\n",
    "\n",
    "The Nextflow configuration file is updated with details about the Azure Batch and Storage environments, and users run pipelines as usual. The only difference is that the path to a shared Azure storage container, which serves as a work directory, must be specified on the Nextflow command line.\n",
    "\n",
    "![Azure Batch integration with Nextflow](img/nextflow-and-azure-batch-integration.png)\n",
    "\n",
    "Nextflow recognizes that the Azure Batch integration is needed when the *azurebatch* executor is specified in the Nextflow configuration file. Nextflow is flexible in this regard and clients can optionally choose to run some process steps in Azure and others locally or in other compute environments.\n",
    "\n",
    "When Nextflow detects that the azurebatch executor is to be used, Nextflow automatically installs and configures the *nf-azure* plug-in. Source code for the plug-in is available on [GitHub](https://github.com/nextflow-io/nextflow/tree/master/plugins/nf-azure). The plug-in implements all the details associated with interacting with Azure Blob storage and managing resources and task execution in the Azure Batch environment.\n",
    "\n",
    "Users can either configure the Azure Batch pools in advance or optionally let Nextflow interact with the Azure Batch API to create resources on the fly using specified VM types and virtual machine images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890af3e",
   "metadata": {},
   "source": [
    "## Configure Azure Batch Environment\n",
    "\n",
    "To configure Azure Batch, you can follow the steps below. These instructions assume that you have a Microsoft Azure account and [contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#contributor) rights in the Azure subscription you want to work with. Also we will use the [Azure Command-Line Interface (CLI)](https://learn.microsoft.com/en-us/cli/azure/) to configure the Azure resources, and SSH to connect to the head node from which we run our Nextflow pipelines. Lets begin with the definition of some parameters which we will use during the process of setting up the Azure environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "827f45a3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#subscriptionName=\"<insert_subscription_to_use>\"\n",
    "\n",
    "resourceGroupName=\"rg_nextflowdemo\"\n",
    "region=\"westeurope\"\n",
    "\n",
    "# between 3 and 24 numbers and lowercase letters only\n",
    "# must be unique within Azure\n",
    "storageAccountName=\"sanextflowdemo\"\n",
    "storageContainerName=\"nfdemocontainer\"\n",
    "\n",
    "# between 3 and 24 numbers and lowercase letters only\n",
    "# must be unique within the region\n",
    "batchAccountName=\"banextflowdemo\"\n",
    "\n",
    "servicePrincipalName=\"SPnfdemo\"\n",
    "\n",
    "# Nextflow headnode parameters\n",
    "vmNFHeadnodeName=\"vm-nf-headnode\"\n",
    "vmNFHeadnodeImage=\"Ubuntu2204\"\n",
    "vmNFHeadnodeSKU=\"Standard_D2as_v5\"\n",
    "vmNFHeadnodeUsername=\"nfuser\"\n",
    "vmNFHeadnodeSSHKey=\"~/.ssh/id_rsa.pub\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8abbdcd",
   "metadata": {},
   "source": [
    "Now lets log in with your Microsoft Azure account and make sure the right subscription is selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd256f05",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "az login --use-device-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014989f5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Set subscription to be used\n",
    "#az account set --subscription $subscriptionName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745fbb5e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Verify you are in the right subscription\n",
    "#az account show --query name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35d475",
   "metadata": {},
   "source": [
    "### Create a Resource Group\n",
    "\n",
    "Run the following [az group create](https://learn.microsoft.com/en-us/cli/azure/group#az-group-create) command to create an Azure resource group named as defined in *resourceGroupName* in the Azure region defined by *region*. The resource group is a logical container that holds the Azure resources for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a078ce8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"/subscriptions/db815c6e-15dd-4853-bfc1-d19a02b68a9b/resourceGroups/rg_nextflowdemo\",\n",
      "  \"location\": \"westeurope\",\n",
      "  \"managedBy\": null,\n",
      "  \"name\": \"rg_nextflowdemo\",\n",
      "  \"properties\": {\n",
      "    \"provisioningState\": \"Succeeded\"\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.Resources/resourceGroups\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "az group create \\\n",
    "    --name $resourceGroupName \\\n",
    "    --location $region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6ddda",
   "metadata": {},
   "source": [
    "### Setup an Azure Storage Account\n",
    "\n",
    "Use the [az storage account create](https://learn.microsoft.com/en-us/cli/azure/storage/account#az-storage-account-create) command to create an [Azure Storage account](https://learn.microsoft.com/en-us/azure/batch/accounts#azure-storage-accounts) which will be linked to your Batch account and be used as working directory. Run the following command to create a *Standard_LRS SKU* storage account named as defined in *storageAccountName* in the resource group we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73f05317",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{/ Finished ..\n",
      "  \"accessTier\": \"Hot\",\n",
      "  \"accountMigrationInProgress\": null,\n",
      "  \"allowBlobPublicAccess\": false,\n",
      "  \"allowCrossTenantReplication\": false,\n",
      "  \"allowSharedKeyAccess\": null,\n",
      "  \"allowedCopyScope\": null,\n",
      "  \"azureFilesIdentityBasedAuthentication\": null,\n",
      "  \"blobRestoreStatus\": null,\n",
      "  \"creationTime\": \"2024-02-13T14:20:43.064156+00:00\",\n",
      "  \"customDomain\": null,\n",
      "  \"defaultToOAuthAuthentication\": null,\n",
      "  \"dnsEndpointType\": null,\n",
      "  \"enableHttpsTrafficOnly\": true,\n",
      "  \"enableNfsV3\": null,\n",
      "  \"encryption\": {\n",
      "    \"encryptionIdentity\": null,\n",
      "    \"keySource\": \"Microsoft.Storage\",\n",
      "    \"keyVaultProperties\": null,\n",
      "    \"requireInfrastructureEncryption\": null,\n",
      "    \"services\": {\n",
      "      \"blob\": {\n",
      "        \"enabled\": true,\n",
      "        \"keyType\": \"Account\",\n",
      "        \"lastEnabledTime\": \"2024-02-13T14:20:43.251633+00:00\"\n",
      "      },\n",
      "      \"file\": {\n",
      "        \"enabled\": true,\n",
      "        \"keyType\": \"Account\",\n",
      "        \"lastEnabledTime\": \"2024-02-13T14:20:43.251633+00:00\"\n",
      "      },\n",
      "      \"queue\": null,\n",
      "      \"table\": null\n",
      "    }\n",
      "  },\n",
      "  \"extendedLocation\": null,\n",
      "  \"failoverInProgress\": null,\n",
      "  \"geoReplicationStats\": null,\n",
      "  \"id\": \"/subscriptions/db815c6e-15dd-4853-bfc1-d19a02b68a9b/resourceGroups/rg_nextflowdemo/providers/Microsoft.Storage/storageAccounts/sanextflowdemo\",\n",
      "  \"identity\": null,\n",
      "  \"immutableStorageWithVersioning\": null,\n",
      "  \"isHnsEnabled\": null,\n",
      "  \"isLocalUserEnabled\": null,\n",
      "  \"isSftpEnabled\": null,\n",
      "  \"isSkuConversionBlocked\": null,\n",
      "  \"keyCreationTime\": {\n",
      "    \"key1\": \"2024-02-13T14:20:43.251633+00:00\",\n",
      "    \"key2\": \"2024-02-13T14:20:43.251633+00:00\"\n",
      "  },\n",
      "  \"keyPolicy\": null,\n",
      "  \"kind\": \"StorageV2\",\n",
      "  \"largeFileSharesState\": null,\n",
      "  \"lastGeoFailoverTime\": null,\n",
      "  \"location\": \"westeurope\",\n",
      "  \"minimumTlsVersion\": \"TLS1_0\",\n",
      "  \"name\": \"sanextflowdemo\",\n",
      "  \"networkRuleSet\": {\n",
      "    \"bypass\": \"AzureServices\",\n",
      "    \"defaultAction\": \"Allow\",\n",
      "    \"ipRules\": [],\n",
      "    \"ipv6Rules\": [],\n",
      "    \"resourceAccessRules\": null,\n",
      "    \"virtualNetworkRules\": []\n",
      "  },\n",
      "  \"primaryEndpoints\": {\n",
      "    \"blob\": \"https://sanextflowdemo.blob.core.windows.net/\",\n",
      "    \"dfs\": \"https://sanextflowdemo.dfs.core.windows.net/\",\n",
      "    \"file\": \"https://sanextflowdemo.file.core.windows.net/\",\n",
      "    \"internetEndpoints\": null,\n",
      "    \"microsoftEndpoints\": null,\n",
      "    \"queue\": \"https://sanextflowdemo.queue.core.windows.net/\",\n",
      "    \"table\": \"https://sanextflowdemo.table.core.windows.net/\",\n",
      "    \"web\": \"https://sanextflowdemo.z6.web.core.windows.net/\"\n",
      "  },\n",
      "  \"primaryLocation\": \"westeurope\",\n",
      "  \"privateEndpointConnections\": [],\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"publicNetworkAccess\": null,\n",
      "  \"resourceGroup\": \"rg_nextflowdemo\",\n",
      "  \"routingPreference\": null,\n",
      "  \"sasPolicy\": null,\n",
      "  \"secondaryEndpoints\": null,\n",
      "  \"secondaryLocation\": null,\n",
      "  \"sku\": {\n",
      "    \"name\": \"Standard_LRS\",\n",
      "    \"tier\": \"Standard\"\n",
      "  },\n",
      "  \"statusOfPrimary\": \"available\",\n",
      "  \"statusOfSecondary\": null,\n",
      "  \"storageAccountSkuConversionStatus\": null,\n",
      "  \"tags\": {},\n",
      "  \"type\": \"Microsoft.Storage/storageAccounts\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "az storage account create \\\n",
    "    --resource-group $resourceGroupName \\\n",
    "    --name $storageAccountName \\\n",
    "    --location $region \\\n",
    "    --sku Standard_LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f180f23",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "az storage container create \\\n",
    "    --name $storageContainerName \\\n",
    "    --account-name $storageAccountName \\\n",
    "    --auth-mode login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11af536c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "storageKey=$(az storage account keys list --resource-group $resourceGroupName --account-name $storageAccountName --query [0].value -o tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a878ff",
   "metadata": {},
   "source": [
    "### Create a Batch Account\n",
    "\n",
    "Run the following [az batch account create](https://learn.microsoft.com/en-us/cli/azure/batch/account#az-batch-account-create) command to create a [Batch account](https://learn.microsoft.com/en-us/azure/batch/accounts#batch-accounts) named as defined in *batchAccountName* in your resource group and link it with the storage account you just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46f239",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "az batch account create \\\n",
    "    --name $batchAccountName \\\n",
    "    --storage-account $storageAccountName \\\n",
    "    --resource-group $resourceGroupName \\\n",
    "    --location $region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceba94e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "batchKey=$(az batch account keys list --name $batchAccountName --resource-group $resourceGroupName --query primary -o tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbdeb45",
   "metadata": {},
   "source": [
    "## Deploy a VM to run Nextflow\n",
    "\n",
    "Even if it is not mandatory, it is generally advisable to start pipelines from a virtual machine (VM) in the cloud and not from a personal desktop or laptop. This is particularly beneficial for workflows that have a long runtime. Although this VM does not function exactly like a cluster head node, it serves a similar purpose by coordinating Azure Batch resources and overseeing the submission and management of workflows.\n",
    "\n",
    "Running pipelines from a VM in the cloud helps reduce data transfer. Users can also conveniently power off their local machines while pipelines are still running, and are protected from temporary network interruptions that could potentially disrupt their workflow.\n",
    "\n",
    "Now create a virtual machine with the az vm create command and store the IP which will be used later to access the machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5415bb35",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "az vm create \\\n",
    "    --resource-group $resourceGroupName \\\n",
    "    --name $vmNFHeadnodeName \\\n",
    "    --size $vmNFHeadnodeSKU \\\n",
    "    --image $vmNFHeadnodeImage \\\n",
    "    --admin-username $vmNFHeadnodeUsername \\\n",
    "    --ssh-key-values $vmNFHeadnodeSSHKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d9a9f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "vmNFHeadnodePubIP=$(az vm show -d -g $resourceGroupName -n $vmNFHeadnodeName --query publicIps -o tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97bd64",
   "metadata": {},
   "source": [
    "## Prepare Headnode and Install Nextflow\n",
    "\n",
    "On the newly provisioned Ubuntu VM, you can do some housekeeping such as updating the apt package index. Install Java since a JVM is required in order to run Nextflow. After installing Java, verify that it runs by running the java from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3278e00",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ssh -o StrictHostKeyChecking=no $vmNFHeadnodeUsername@$vmNFHeadnodePubIP \\\n",
    "    'sudo apt update; \\\n",
    "    sudo apt install -y default-jdk; \\\n",
    "    java -version'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95059a",
   "metadata": {},
   "source": [
    "Install Nextflow as shown below or follow the [installation instructions](https://www.nextflow.io/docs/latest/getstarted.html#installation) in the Nextflow documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0b0df",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ssh $vmNFHeadnodeUsername@$vmNFHeadnodePubIP 'wget -qO- https://get.nextflow.io | bash'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b139c",
   "metadata": {},
   "source": [
    "Next, we can verify that Nextflow is working properly by executing the popular “hello” pipeline directly from the [Nextflow GitHub repo](https://github.com/nextflow-io/hello):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d80c9c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ssh $vmNFHeadnodeUsername@$vmNFHeadnodePubIP './nextflow run hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fee51",
   "metadata": {},
   "source": [
    "## Configure Nextflow to Use Azure Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd5535",
   "metadata": {},
   "source": [
    "At this point our Azure Batch environment is set up, and we have a functional Nextflow environment in Azure. The next step is to configure Nextflow to dispatch work to Azure Batch.\n",
    "\n",
    "Details about the Azure Batch and storage settings need to be specified in the Nextflow configuration file. Configuration settings can exist in multiple locations as described in the [Nextflow documentation](https://www.nextflow.io/docs/latest/config.html). In this example, we will configure settings in $HOME/nextflow/config and make Azure Batch our default execution environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a0fd0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cat <<EOF | ssh $vmNFHeadnodeUsername@$vmNFHeadnodePubIP \"cat >>.nextflow/config\"\n",
    "process {\n",
    "  executor = 'azurebatch'\n",
    "}\n",
    "\n",
    "azure {\n",
    "\n",
    "    storage {\n",
    "        accountName = '$storageAccountName'\n",
    "        accountKey = '$storageKey'\n",
    "    }\n",
    "\n",
    "    batch {\n",
    "        accountName = '$batchAccountName'\n",
    "        accountKey = '$batchKey'\n",
    "        location = '$region'\n",
    "        autoPoolMode = true\n",
    "        allowPoolCreation = true\n",
    "        pools {\n",
    "            auto {\n",
    "                autoScale = true\n",
    "                vmCount = 1\n",
    "                maxVmCount = 10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b07edc",
   "metadata": {},
   "source": [
    "With details about the Azure Batch configuration present in the Nextflow config file, we can run one of the sample Nextflow workflows. You will need to supply the name of the storage container that you specified when you set up the Azure Storage account as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941a80f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ssh $vmNFHeadnodeUsername@$vmNFHeadnodePubIP \"./nextflow run https://github.com/nextflow-io/rnaseq-nf -w az://$storageContainerName/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1936ed8",
   "metadata": {},
   "source": [
    "Assuming that all of the credentials have been entered correctly, you should see the pipeline execute as normal. The only difference is that the Nextflow Azure integration is transparently shifting execution to a dynamically provisioned resources pool managed by Azure Batch. Execution will typically take a couple of minutes, because Azure needs to dynamically create a resource pool and start VMs to handle the pipeline tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a614190",
   "metadata": {},
   "source": [
    "## Cleanup all resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c938fd91",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K / Finished .."
     ]
    }
   ],
   "source": [
    "az group delete --yes --name $resourceGroupName"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
